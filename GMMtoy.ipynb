{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@inproceedings{\n",
    "    manor2024posterior,\n",
    "    title={On the Posterior Distribution in Denoising: Application to Uncertainty Quantification},\n",
    "    author={Hila Manor and Tomer Michaeli},\n",
    "    booktitle={The Twelfth International Conference on Learning Representations},\n",
    "    year={2024},\n",
    "    url={https://openreview.net/forum?id=adSGeugiuj}\n",
    "}\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import subprocess # inkspace\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multivariate_gaussian_mixture(M: int, mus: np.array, sigmas: np.array, N: int = 10000, weights: np.array = None) -> np.array:\n",
    "    \"\"\"\n",
    "    Sample data points from a Gaussian Mixture Model (GMM) using the Component Selection Method.\n",
    "    \n",
    "    This function first generates samples from all individual multivariate Gaussian distributions \n",
    "    and then selects one component per data point based on the given mixture weights.\n",
    "\n",
    "    Sampling process:\n",
    "    1. Generate an array of shape (N, d, M), where each column represents samples drawn from \n",
    "       a different Gaussian component.\n",
    "    2. Randomly select one component for each data point according to the specified `weights`.\n",
    "    3. Return the selected samples, ensuring that the final output has the shape (N, d).\n",
    "\n",
    "    Parameters:\n",
    "        M (int): Number of Gaussian components in the mixture.\n",
    "        mus (list of np.array): List of mean vectors for each Gaussian component, \n",
    "                                where each element is a (d,) numpy array.\n",
    "        sigmas (list of np.array): List of covariance matrices for each Gaussian component, \n",
    "                                   where each element is a (d, d) numpy array.\n",
    "        N (int): Number of data points to sample.\n",
    "        weights (list or np.array, optional): Probability weights for selecting each Gaussian \n",
    "                                              component. If None, all components are assumed \n",
    "                                              to be equally weighted (1/M).\n",
    "\n",
    "    Returns:\n",
    "        np.array: An array of shape (N, d), where each row is a sampled data point.\n",
    "    \"\"\"\n",
    "\n",
    "    assert (M == len(mus))\n",
    "    \n",
    "    samples = np.zeros((N, len(mus[0]), M), dtype=np.float64)\n",
    "    for i in range(M):\n",
    "        samples[:, :, i] = np.random.multivariate_normal(mus[i], sigmas[i], size=(N,)).astype(np.float64)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(M, dtype=np.float64) / M\n",
    "    random_idx = np.random.choice(np.arange(M), size=(N,), p=weights)\n",
    "    return samples[np.arange(N), :, random_idx]\n",
    "\n",
    "def generate_gaussian_kernel(kernel_size: int, sigma: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates Gaussian blur kernel.\n",
    "    params:\n",
    "        kernel_size: the kernel size\n",
    "        sigma: the blurring level/ variance\n",
    "    \"\"\"\n",
    "    ax = np.linspace(-(kernel_size // 2), kernel_size // 2, kernel_size)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sigma))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "\n",
    "\n",
    "def construct_toeplitz_for_convolution(kernel: np.array, input_size: tuple) ->np.array:\n",
    "    \"\"\"\n",
    "    Construct Toeplitzmatrix to implement convolution.\n",
    "    \n",
    "    params:\n",
    "        kernel: (k_h, k_w) kernel\n",
    "        input_size: (H, W) size of the input image\n",
    "\n",
    "    return:\n",
    "        Toeplitz matrix (H * W, H * W)\n",
    "    \"\"\"\n",
    "    H, W = input_size\n",
    "    k_h, k_w = kernel.shape  # the shape of kernel\n",
    "    num_pixels = H * W  # fatten size\n",
    "\n",
    "    # Calculate the outputshape (same padding, s.t. input and output share the same shape)\n",
    "    output_size = num_pixels\n",
    "\n",
    "    # Initialize Toeplitz matrix\n",
    "    toeplitz_matrix = np.zeros((output_size, num_pixels))\n",
    "\n",
    "    # Construct Toeplitz structure by traversing every pixel.\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            idx = i * W + j  # Current pixel index\n",
    "            window = np.zeros((H, W))\n",
    "            i_start = max(i - k_h // 2, 0)\n",
    "            j_start = max(j - k_w // 2, 0)\n",
    "            i_end = min(i + k_h // 2 + 1, H)\n",
    "            j_end = min(j + k_w // 2 + 1, W)\n",
    "\n",
    "            # put the kernel at a proper place\n",
    "            window[i_start:i_end, j_start:j_end] = kernel[\n",
    "                i_start - i + k_h // 2:i_end - i + k_h // 2,\n",
    "                j_start - j + k_w // 2:j_end - j + k_w // 2,\n",
    "            ]\n",
    "            toeplitz_matrix[idx, :] = window.flatten()\n",
    "\n",
    "    return toeplitz_matrix\n",
    "\n",
    "\n",
    "def mu1_real_blur(y: np.array ,A: np.array, sigma1: np.array, sigma2: np.array, Nsigma: np.array, m1: np.array, m2: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Calculates the theoretical posterier E(x|y) of a two-component GMM\n",
    "        y: (d, N), blurred image\n",
    "        A: (N, N), The toeplitz matrix of the blurring process \n",
    "        sigma1: (d, d). The covariance matrix 1\n",
    "        sigma2: (d, d). The covariance matrix 2\n",
    "        Nsigma; (d, d). The covariance matrix of the noise. Non-diagonal elements are all zero.\n",
    "        m1, m2: (d, 1). prior mean of two component distributions\n",
    "    \"\"\"\n",
    "    y = y.astype(np.float64)\n",
    "    \n",
    "    mu1_post = m1 + sigma1 @ A.T @ np.linalg.inv(A @ sigma1 @ A.T + Nsigma) @ (y - A @ m1)\n",
    "    mu2_post = m2 + sigma2 @ A.T @ np.linalg.inv(A @ sigma2 @ A.T + Nsigma) @ (y - A @ m2)\n",
    "\n",
    "    # Calculate the weights of individual Gaussian distributions.\n",
    "    p1 = np.diag(np.exp(-0.5 * (y - A @ m1).T @ np.linalg.inv(A @ sigma1 @ A.T + Nsigma) @ (y - A @ m1)))\n",
    "    p2 = np.diag(np.exp(-0.5 * (y - A @ m2).T @ np.linalg.inv(A @ sigma2 @ A.T + Nsigma) @ (y - A @ m2)))\n",
    "\n",
    "    return (mu1_post * p1 + mu2_post * p2) / (p1 + p2)\n",
    "\n",
    "\n",
    "def px_pdf_real(xs, sigma1, sigma2, m1, m2):\n",
    "    # Calculate the pdf of a wo-component Gaussian Mixture Model (GMM)\n",
    "    xs = xs.astype(np.float64)\n",
    "    norm_const1 = 1 / (2* np.pi * np.linalg.det(sigma1))\n",
    "    norm_const2 = 1 / (2* np.pi * np.linalg.det(sigma2))\n",
    "    pdf1 = norm_const1 * np.diag(np.exp(-0.5 * (xs - m1).T @ np.linalg.inv((sigma1)) @ (xs - m1)))\n",
    "    pdf2 = norm_const2 * np.diag(np.exp(-0.5 * (xs - m2).T @ np.linalg.inv((sigma2)) @ (xs - m2)))\n",
    "    return 0.5 * pdf1 + 0.5 * pdf2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "np.random.seed(30)\n",
    "# import seaborn as sns\n",
    "# sns.set_style('white')\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"cmu-serif\",\n",
    "    \"mathtext.fontset\": \"cm\",\n",
    "    \"font.size\": 18\n",
    "})\n",
    "# GMM sampling\n",
    "mus = [np.array([1, 2]), np.array([8, 10])]\n",
    "sigmas = [np.array([[1, 0], [0, 2]]), np.array([[2, 1], [1, 1]])]\n",
    "sigma1, sigma2 = sigmas\n",
    "m1, m2 = mus\n",
    "m1, m2 = m1.reshape(2,1), m2.reshape(2,1)\n",
    "x = sample_multivariate_gaussian_mixture(2, mus, sigmas, weights=np.array([0.5, 0.5])).astype(np.float64)\n",
    "x = x.T \n",
    "# Generate the convolution kernel\n",
    "print(generate_gaussian_kernel(3, 3).shape)\n",
    "A1 = construct_toeplitz_for_convolution(generate_gaussian_kernel(3, 3), (100,100)) # assume 2*10000 is a 2 channels 100 * 100 image\n",
    "A2 = construct_toeplitz_for_convolution(generate_gaussian_kernel(3, 3), (100,100))\n",
    "y1 = A1 @ x[0]\n",
    "y2 = A2 @ x[1]\n",
    "\n",
    "# Generagte noise\n",
    "noise_sigma2 = 4\n",
    "Nsigma = noise_sigma2 * np.eye(2)\n",
    "n = np.random.multivariate_normal(np.array([0, 0]), Nsigma, (len(x.T),)).astype(np.float64).T\n",
    "\n",
    "Ax = np.vstack([y1, y2])\n",
    "y = Ax + n\n",
    "print(A1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f = np.fft.fft2(x.reshape(2, 100, 100))  # 计算 x 的频域表示\n",
    "H_f = np.fft.fft2(generate_gaussian_kernel(3, 3), s=(100, 100))  # 计算卷积核的 FFT\n",
    "y_t = np.fft.ifft2(Y_f, axes=(1, 2)).real  # 取实部，形状仍然是 (2, 100, 100)\n",
    "\n",
    "# 重新展平为 (2, 10000)\n",
    "y_t = y_t.reshape(2, 10000)\n",
    "\n",
    "# 生成噪声，确保形状匹配\n",
    "noise_sigma2 = 4\n",
    "Nsigma = noise_sigma2 * np.eye(2)\n",
    "n = np.random.multivariate_normal(np.array([0, 0]), Nsigma, (10000,)).T  # 形状 (2, 10000)\n",
    "\n",
    "# 计算最终的 y\n",
    "y_t = y_t + n  # 形状匹配，正确计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error: 5.606768e-01\n"
     ]
    }
   ],
   "source": [
    "diff = np.linalg.norm(y_t - y, ord='fro') / np.linalg.norm(y, ord='fro')\n",
    "print(f\"Relative error: {diff:.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割训练集和测试集\n",
    "train_samples_x = x[:, :int(x.shape[-1] * 0.8)]\n",
    "test_samples_x  = x[:, int(x.shape[-1] * 0.8):]\n",
    "train_samples_y = y[:, :int(y.shape[-1] * 0.8)]\n",
    "test_samples_y  = y[:, int(y.shape[-1] * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x300 with 0 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# (1) p(x) vs p(y)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(test_samples_y[0], test_samples_y[1], marker='.', color='red', alpha=1, label='y (模糊后)')\n",
    "plt.scatter(test_samples_x[0], test_samples_x[1], marker='.', color='green', alpha=0.7, label='x (真实)')\n",
    "plt.legend()\n",
    "plt.title('$p(x)$ vs $p(y)$')\n",
    "\n",
    "# (2) p(y) vs p(x|y)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(test_samples_y[0], test_samples_y[1], marker='.', color='red', alpha=1, label='y (模糊后)')\n",
    "plt.scatter(mu1_real_res[0], mu1_real_res[1], marker='.', color='blue', alpha=0.7, label='x$|$y (去模糊后)')\n",
    "plt.legend()\n",
    "plt.title('$p(y)$ vs $p(x|y)$')\n",
    "\n",
    "# (3) p(x) vs p(x|y)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(test_samples_x[0], test_samples_x[1], marker='.', color='green', alpha=1, label='x (真实)')\n",
    "plt.scatter(mu1_real_res[0], mu1_real_res[1], marker='.', color='blue', alpha=0.7, label='x$|$y (去模糊后)')\n",
    "plt.legend()\n",
    "plt.title('$p(x)$ vs $p(x|y)$')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
